<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Boosting AI Performance: Networking for AI Inference — PTD Today</title>
  <meta name="description" content="Based on the available description, Victor Moreno (Product Manager, Cloud Networking at Google) explains how AI-aware networking—using GKE Inference Gateway and Cloud Load Balancin" />
  <link rel="canonical" href="https://ptdtoday.com/media/kicTHogP2gU.html" />

  <meta property="og:type" content="article" />
  <meta property="og:site_name" content="PTD Today" />
  <meta property="og:title" content="Boosting AI Performance: Networking for AI Inference" />
  <meta property="og:description" content="Based on the available description, Victor Moreno (Product Manager, Cloud Networking at Google) explains how AI-aware networking—using GKE Inference Gateway and Cloud Load Balancin" />
  <meta property="og:url" content="https://ptdtoday.com/media/kicTHogP2gU.html" />
  <meta property="og:image" content="https://i.ytimg.com/vi/kicTHogP2gU/hqdefault.jpg" />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Boosting AI Performance: Networking for AI Inference" />
  <meta name="twitter:description" content="Based on the available description, Victor Moreno (Product Manager, Cloud Networking at Google) explains how AI-aware networking—using GKE Inference Gateway and Cloud Load Balancin" />
  <meta name="twitter:image" content="https://i.ytimg.com/vi/kicTHogP2gU/hqdefault.jpg" />

  <script type="application/ld+json">{&quot;@context&quot;:&quot;https://schema.org&quot;,&quot;@type&quot;:&quot;Article&quot;,&quot;headline&quot;:&quot;Boosting AI Performance: Networking for AI Inference&quot;,&quot;description&quot;:&quot;Based on the available description, Victor Moreno (Product Manager, Cloud Networking at Google) explains how AI-aware networking—using GKE Inference Gateway and Cloud Load Balancin&quot;,&quot;datePublished&quot;:&quot;2026-01-14T19:29:22.000Z&quot;,&quot;dateModified&quot;:&quot;2026-01-16T04:59:41.053Z&quot;,&quot;mainEntityOfPage&quot;:&quot;https://ptdtoday.com/media/kicTHogP2gU.html&quot;,&quot;publisher&quot;:{&quot;@type&quot;:&quot;Organization&quot;,&quot;name&quot;:&quot;PTD Today&quot;}}</script>
  

  <style>
    :root{
      --bg:#ffffff; --ink:#111; --muted:#5c5c5c; --rule:rgba(0,0,0,.15); --soft:rgba(0,0,0,.06);
      --pill:rgba(0,0,0,.04); --btn:#111; --btnInk:#fff;
    }
    *{box-sizing:border-box}
    body{margin:0;background:var(--bg);color:var(--ink);font-family:Georgia,"Times New Roman",Times,serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility}
    a{color:inherit}
    .wrap{max-width:900px;margin:0 auto;padding:26px 16px 64px}
    .mast{text-align:center;padding:16px 0 10px}
    .brand{margin:0;font-size:52px;letter-spacing:.2px;font-weight:700}
    .tagline{margin:6px 0 10px;color:var(--muted);font-style:italic;font-size:16px}
    .nav{display:flex;justify-content:center;gap:14px;flex-wrap:wrap;margin:10px 0 10px}
    .nav a{text-decoration:none;padding:7px 12px;border-radius:999px;border:1px solid transparent;color:rgba(0,0,0,.75);font-size:15px}
    .nav a:hover{border-color:var(--rule);background:rgba(0,0,0,.02)}
    .nav a.active{border-color:var(--rule);background:rgba(0,0,0,.03);font-weight:700;color:rgba(0,0,0,.92)}
    .rule{height:1px;background:var(--rule);margin:14px 0 0}
    .meta{color:var(--muted);font-size:12px;letter-spacing:.14px;text-transform:uppercase;margin:16px 0 8px}
    h1{margin:0 0 10px;font-size:44px;line-height:1.03;font-weight:900}
    .lede{font-size:18px;line-height:1.6;color:rgba(0,0,0,.86);margin:0 0 14px}
    .card{border:1px solid var(--rule);border-radius:14px;overflow:hidden;background:#fff}
    .thumb img{width:100%;display:block}
    .content{padding:14px}
    .subhead{margin:18px 0 8px;font-size:12px;text-transform:uppercase;letter-spacing:.12px;color:var(--muted)}
    ul{margin:0 0 12px;padding-left:18px}
    li{margin:6px 0}
    .chips{display:flex;gap:8px;flex-wrap:wrap;margin:14px 0 0}
    .chip{display:inline-flex;align-items:center;padding:7px 10px;border-radius:999px;border:1px solid var(--rule);background:var(--pill);font-size:13px;color:rgba(0,0,0,.76)}
    .btnRow{display:flex;gap:10px;flex-wrap:wrap;margin:16px 0 0}
    .btn{appearance:none;border:1px solid var(--rule);background:var(--btn);color:var(--btnInk);padding:9px 14px;border-radius:999px;cursor:pointer;font-family:inherit;font-size:14px;text-decoration:none;display:inline-flex;align-items:center;justify-content:center}
    .btn.secondary{background:#fff;color:#111}
    .footer{text-align:center;margin-top:24px;color:var(--muted);font-size:13px}
    @media (max-width:760px){.brand{font-size:44px}h1{font-size:38px}}
  </style>
</head>
<body>
  <div class="wrap">
    <header class="mast">
      <h1 class="brand">PTD Today</h1>
      <div class="tagline">First to Know. First to Lead.</div>
      <nav class="nav" aria-label="Primary navigation">
        <a href="/index.html">Home</a>
        <a href="/room.html">Room</a>
        <a class="active" href="/media.html">Media</a>
      </nav>
      <div class="rule"></div>
    </header>

    <div class="meta">VIDEO • Google Cloud • 2026-01-14T19:29:22.000Z</div>
    <h1>Boosting AI Performance: Networking for AI Inference</h1>
    <p class="lede">Based on the available description, Victor Moreno (Product Manager, Cloud Networking at Google) explains how AI-aware networking—using GKE Inference Gateway and Cloud Load Balancing—optimizes AI inference by routing on inference-specific signals (KV cache utilization, queue depth) rather than traditional CPU metrics. The approach adds prefix/body-based routing, LoRA adapter awareness and Service Extensions (network-level API/guardrail insertion) to reduce cold starts, maximize GPU utilization, lower latency and cut wasted compute.</p>

    <div class="card">
      <div class="thumb">
        <img src="https://i.ytimg.com/vi/kicTHogP2gU/hqdefault.jpg" alt="">
      </div>
      <div class="content">
        <div class="btnRow">
          <a class="btn" href="https://www.youtube.com/watch?v=kicTHogP2gU" target="_blank" rel="noopener">Watch on YouTube</a>
          <button class="btn secondary" id="shareBtn" type="button">Share</button>
        </div>

        
          <div class="subhead">Key points</div>
          <ul><li>Traditional networking and round-robin load balancers miss GPU congestion because CPU metrics don’t reflect inference load.</li><li>GKE Inference Gateway and AI-aware load balancing use specialized metrics (KV cache utilization, queue depth) to identify least-loaded replicas.</li><li>Prefix caching and shadow copies let the gateway reuse prefill computations to reduce GPU work and latency for common prompts.</li><li>Body-based routing and LoRA-awareness enable routing to the correct model/adapter instance without complex topologies.</li><li>Service Extensions let organizations insert API management and AI guardrails at the network edge to sanitize requests before they hit GPUs.</li></ul>
        

        
          <div class="subhead">So what</div>
          <ul><li>Better GPU saturation and fewer cold starts can lower overall power draw per inference and improve data center energy efficiency.</li><li>Routing that reduces wasted GPU cycles (via cache reuse and edge sanitization) can cut compute costs and avoid unnecessary thermal load or peak power events.</li><li>Network-layer guardrails reduce wasted inference workload, helping control OPEX and reduce marginal energy and cooling demands.</li><li>Unified, network-aware routing simplifies deployment and can reduce operational complexity for large AI fleets—helpful for capacity planning and asset utilization.</li><li>Edge sanitization and routing choices can influence when and how workloads run, which matters for scheduling demand, on-site backup power sizing, and integration with renewables or storage.</li></ul>
        

        
          <div class="chips">
            <span class="chip">AI-inference</span><span class="chip">networking</span><span class="chip">GKE-Inference-Gateway</span><span class="chip">load-balancing</span><span class="chip">GPU-utilization</span><span class="chip">prefix-caching</span><span class="chip">service-extensions</span><span class="chip">guardrails</span><span class="chip">Google-Cloud</span>
          </div>
        
      </div>
    </div>

    <div class="footer">© 2026 PTD Today</div>
  </div>

  <script>
    (function(){
      var url = "https://ptdtoday.com/media/kicTHogP2gU.html";
      var title = "Boosting AI Performance: Networking for AI Inference";
      var text = "Based on the available description, Victor Moreno (Product Manager, Cloud Networking at Google) explains how AI-aware networking—using GKE Inference Gateway and Cloud Load Balancin";
      var btn = document.getElementById("shareBtn");
      if(!btn) return;
      btn.addEventListener("click", async function(){
        if (navigator.share) {
          try { await navigator.share({ title: title, text: text, url: url }); return; }
          catch(e){ return; }
        }
        try{
          await navigator.clipboard.writeText(url);
          alert("Link copied.");
        }catch(e){
          prompt("Copy this link:", url);
        }
      });
    })();
  </script>
</body>
</html>